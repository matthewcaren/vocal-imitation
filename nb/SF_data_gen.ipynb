{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbb53a41-2b26-46ce-b971-b0e16fedbd1f",
   "metadata": {},
   "source": [
    "# Source-Filter Utterance Data Generation\n",
    "*This notebook uses a FAUST implementation of a source-filter model of the vocal tract to generate a dataset of synthetic utterances.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22dfa68-09ea-4dd9-bb79-85207cc36c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchaudio\n",
    "from faust_ctypes.wrapper import Faust\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from RSA_helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dead63a6-04ea-4101-9f62-51a20bb58ca7",
   "metadata": {},
   "source": [
    "## Define params & test synthesis pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d554525c-e836-4186-9ce0-ad14b830434b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp = Faust(\"../faust_dsp/SF_voc_synth_f.so\")\n",
    "samples = dsp.proc.compute(100000)\n",
    "Audio(samples, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26af76de-e719-4893-9171-98c35ac86379",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "torch.set_default_dtype(torch.float)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94cf203-5cbc-4a1d-91b8-000c679f0b8f",
   "metadata": {},
   "source": [
    "## Synth function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab5e2b9-b6ee-4802-a34b-87bfece7504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_voice(params_sequence):\n",
    "    n_control_steps = params_sequence.shape[0]\n",
    "    params_seq_list = params_sequence.tolist()\n",
    "    output = np.zeros(n_control_steps*AUDIO_SR//CONTROL_SR, dtype=np.float32)\n",
    "    state = params_sequence[0,:]\n",
    "\n",
    "    # warm-up\n",
    "    dsp.proc.compute(500)\n",
    "    \n",
    "    for i in range(n_control_steps):\n",
    "        dsp.ui.b_vocal.p_freq.zone = params_sequence[i, 0].item() + 0.01*np.random.rand()\n",
    "        dsp.ui.b_vocal.p_gain.zone = params_sequence[i, 1].item()\n",
    "        dsp.ui.b_vocal.p_vowel.zone = params_sequence[i, 2].item() + 0.02*np.random.rand()\n",
    "        dsp.ui.b_vocal.p_fricative.zone = (params_sequence[i, 3].item() > 0.99)\n",
    "        dsp.ui.b_vocal.p_plosive.zone = (params_sequence[i, 4].item() > 0.2)\n",
    "        output[i*AUDIO_SR//CONTROL_SR : (i+1)*AUDIO_SR//CONTROL_SR] = dsp.proc.compute(AUDIO_SR//CONTROL_SR)\n",
    "\n",
    "    return torch.tensor(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1488b01f-0c10-4287-b357-61b6143a61a8",
   "metadata": {},
   "source": [
    "## Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da28a5-14f6-4002-a4ca-655b51994cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_walk_data():\n",
    "    synth_params = torch.zeros((N_SAMPLES, SAMPLE_LEN, N_VOCAL_TRACT_CONTROLS))\n",
    "    \n",
    "    for sample_idx in range(N_SAMPLES):\n",
    "        state = torch.rand(N_VOCAL_TRACT_CONTROLS)   # freq, vowel, fric\n",
    "        for step_idx in range(SAMPLE_LEN):\n",
    "            synth_params[sample_idx, step_idx, :] = torch.sin(state)*0.5 + 0.5   # write state\n",
    "            state += torch.rand(N_VOCAL_TRACT_CONTROLS)*0.5   # update state\n",
    "    \n",
    "    for sample_idx in range(N_SAMPLES):\n",
    "        synthesized_audio = synthesize_voice(synth_params[sample_idx,:,:])\n",
    "        torchaudio.save(VOCAL_DATA_DIR+'synth_'+str(sample_idx) + '.wav', synthesized_audio.unsqueeze(0), sample_rate=AUDIO_SR)\n",
    "    \n",
    "    torch.save(synth_params, VOCAL_DATA_DIR+'params.pt')\n",
    "\n",
    "\n",
    "def generate_grid_osc_data():\n",
    "    for controls_tup in itertools.product(range(0, N_GRID_SEQ_TYPE), repeat=N_VOCAL_TRACT_CONTROLS):\n",
    "        if 0 in controls_tup or 1 in controls_tup or 2 in controls_tup or 3 in controls_tup:\n",
    "            synth_params = torch.zeros((SAMPLE_LEN, N_VOCAL_TRACT_CONTROLS))\n",
    "            for control_num in range(N_VOCAL_TRACT_CONTROLS):\n",
    "                seq_order = controls_tup[control_num]\n",
    "                synth_params[:,control_num] = lookup_grid_seq(seq_order, SAMPLE_LEN)\n",
    "        \n",
    "            synthesized_audio = synthesize_voice(synth_params)\n",
    "            torchaudio.save(VOCAL_DATA_DIR + f\"{'-'.join(map(str,controls_tup))}.wav\", synthesized_audio.unsqueeze(0), sample_rate=AUDIO_SR)\n",
    "\n",
    "\n",
    "def lookup_grid_seq(seq_order, length):\n",
    "    # constant\n",
    "    if seq_order <= 3:\n",
    "        return 0.33*seq_order*torch.ones(SAMPLE_LEN)\n",
    "\n",
    "    # sine\n",
    "    elif seq_order <= 6:\n",
    "        return 0.5 + 0.4*torch.sin(torch.linspace(0,SAMPLE_LEN//CONTROL_SR,steps=SAMPLE_LEN)*2*math.pi*(seq_order-3))\n",
    "\n",
    "    # sine biased hi\n",
    "    elif seq_order <= 7:\n",
    "        return 0.75 + 0.25*torch.sin(torch.linspace(0,SAMPLE_LEN//CONTROL_SR,steps=SAMPLE_LEN)*2*math.pi*(seq_order-5))\n",
    "\n",
    "    # sine biased low\n",
    "    elif seq_order <= 8:\n",
    "        return 0.25 + 0.25*torch.sin(torch.linspace(0,SAMPLE_LEN//CONTROL_SR,steps=SAMPLE_LEN)*2*math.pi*(seq_order-6))\n",
    "\n",
    "    # falling saw\n",
    "    elif seq_order <= 9:\n",
    "        return 1 - (torch.linspace(0, SAMPLE_LEN*(seq_order-7), steps=SAMPLE_LEN) % 1)\n",
    "\n",
    "    # random\n",
    "    else:\n",
    "        return torch.rand(SAMPLE_LEN//3 + 3).repeat_interleave(3)[:SAMPLE_LEN]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c01c2d2-4e26-49d3-8bab-cc488aa22b8b",
   "metadata": {},
   "source": [
    "## Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a629b841-aef1-4b1b-a8cc-35c84a582265",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_grid_osc_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
